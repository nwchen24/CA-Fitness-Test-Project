{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w209 Final Project Load Data\n",
    "\n",
    "This code loads and processes the fitnessgram and academic test results into a dataset that will ultimately be used in our final project visualization.  \n",
    "\n",
    "The resulting dataset has observations for each school, district, county, subgroup (e.g. male, female, black, hispanic, economically disadvantaged, etc.). The fitness data reported for each of these observations are the percentage of 5th, 7th, and 9th grade students in the healthy fitness zone, need improvement fitness zone, and high risk fitness zone for aerobic capacity and body composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#*******************************************************************************\n",
    "#*******************************************************************************\n",
    "#Set these file paths for your own local machine before running\n",
    "#*******************************************************************************\n",
    "#*******************************************************************************\n",
    "\n",
    "#Set file path containing fitnessgram data\n",
    "fitnessgram_datapath = \"/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Fitnessgram_Results\"\n",
    "\n",
    "#Set file path containing academic test data\n",
    "academic_datapath = \"/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Test_Results\"\n",
    "\n",
    "#Set file path where you want to write the combined data\n",
    "combined_datapath = '/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Combined_Data/Combined_Physical_Fitness_Data.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FitnessGram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize lists to hold filepaths\n",
    "Phys_files_list = []\n",
    "Entities_files_list = []\n",
    "\n",
    "#Walk the data directory and get all filepaths\n",
    "for root, dirs, files in os.walk(fitnessgram_datapath):\n",
    "    for filename in files:\n",
    "        #Get full list of filepaths to the physical fitness test files\n",
    "        if filename.endswith('.txt'):    \n",
    "            if filename[:4] == \"Phys\":\n",
    "                Phys_files_list.append(fitnessgram_datapath + \"/PFT_\" + filename[7:11] + \"/\" + filename)\n",
    "            if filename[8:16] == \"Research\":\n",
    "                Phys_files_list.append(fitnessgram_datapath + \"/PFT_\" + str(int(filename[:4])+1) + \"/\" + filename)\n",
    "\n",
    "            #Get full list of filepaths to the entities files        \n",
    "            if filename[:8] == \"Entities\":\n",
    "                Entities_files_list.append(fitnessgram_datapath + \"/PFT_\" + filename[8:13] + \"/\" + filename)\n",
    "            if filename[8:16] == \"Entities\":\n",
    "                Entities_files_list.append(fitnessgram_datapath + \"/PFT_\" + str(int(filename[:4])+1) + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "(2233435, 24)\n",
      "Index([u'Level_Number', u'Report_Number', u'Table_Number', u'Line_Number',\n",
      "       u'CO', u'DIST', u'SCHL', u'Line_Text', u'NoStud5', u'NoHFZ5', u'Perc5a',\n",
      "       u'Perc5b', u'Perc5c', u'NoStud7', u'NoHFZ7', u'Perc7a', u'Perc7b',\n",
      "       u'Perc7c', u'NoStud9', u'NoHFZ9', u'Perc9a', u'Perc9b', u'Perc9c',\n",
      "       u'ChrtNum'],\n",
      "      dtype='object')\n",
      "2015\n",
      "(2255801, 24)\n",
      "Index([u'Level_Number', u'Report_Number', u'Table_Number', u'Line_Number',\n",
      "       u'CO', u'DIST', u'SCHL', u'Line_Text', u'NoStud5', u'NoHFZ5', u'Perc5a',\n",
      "       u'Perc5b', u'Perc5c', u'NoStud7', u'NoHFZ7', u'Perc7a', u'Perc7b',\n",
      "       u'Perc7c', u'NoStud9', u'NoHFZ9', u'Perc9a', u'Perc9b', u'Perc9c',\n",
      "       u'ChrtNum'],\n",
      "      dtype='object')\n",
      "2016\n",
      "(2279222, 24)\n",
      "Index([u'Level_Number', u'Report_Number', u'Table_Number', u'Line_Number',\n",
      "       u'CO', u'DIST', u'SCHL', u'Line_Text', u'NoStud5', u'NoHFZ5', u'Perc5a',\n",
      "       u'Perc5b', u'Perc5c', u'NoStud7', u'NoHFZ7', u'Perc7a', u'Perc7b',\n",
      "       u'Perc7c', u'NoStud9', u'NoHFZ9', u'Perc9a', u'Perc9b', u'Perc9c',\n",
      "       u'ChrtNum'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#get list of all columns in the file from each year\n",
    "Phys_col_list = []\n",
    "\n",
    "#read PhysFit files and append column names to the list\n",
    "for filepath in Phys_files_list:\n",
    "    \n",
    "    if int(filepath[73:77]) < 2014:\n",
    "        pass\n",
    "    \n",
    "    elif (int(filepath[73:77]) >= 2014):\n",
    "        #read the file\n",
    "        temp_df = pd.read_csv(filepath)\n",
    "        #print the shape\n",
    "        print filepath[73:77]\n",
    "        print temp_df.shape\n",
    "        #get the columns\n",
    "        temp_col_list = temp_df.columns\n",
    "        #add columns not already encountered to the column list\n",
    "        for colname in temp_col_list:\n",
    "            if colname not in Phys_col_list:\n",
    "                Phys_col_list.append(colname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Level_Number',\n",
       " 'Report_Number',\n",
       " 'Table_Number',\n",
       " 'Line_Number',\n",
       " 'CO',\n",
       " 'DIST',\n",
       " 'SCHL',\n",
       " 'Line_Text',\n",
       " 'NoStud5',\n",
       " 'NoHFZ5',\n",
       " 'Perc5a',\n",
       " 'Perc5b',\n",
       " 'Perc5c',\n",
       " 'NoStud7',\n",
       " 'NoHFZ7',\n",
       " 'Perc7a',\n",
       " 'Perc7b',\n",
       " 'Perc7c',\n",
       " 'NoStud9',\n",
       " 'NoHFZ9',\n",
       " 'Perc9a',\n",
       " 'Perc9b',\n",
       " 'Perc9c',\n",
       " 'ChrtNum']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The columns are consistent among the 2014 - 2016 files\n",
    "Phys_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 Read Successfully\n",
      "2015 Read Successfully\n",
      "2016 Read Successfully\n"
     ]
    }
   ],
   "source": [
    "#initialize dataframe to hold the physical fitness files\n",
    "Physfit_df = pd.DataFrame(columns = Phys_col_list)\n",
    "\n",
    "#read PhysFit files\n",
    " \n",
    "\n",
    "for filepath in Phys_files_list:\n",
    "    if int(filepath[73:77]) < 2014:\n",
    "        pass\n",
    "    \n",
    "    elif (int(filepath[73:77]) >= 2014):\n",
    "        temp_df = pd.read_csv(filepath)\n",
    "        #temp_df = temp_df.rename(columns = Physfit_column_mapping)\n",
    "        temp_df['Year'] = filepath[73:77]\n",
    "        Physfit_df = Physfit_df.append(temp_df)\n",
    "        print filepath[73:77] + \" Read Successfully\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Data to Keep only Observations we Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nwchen24/anaconda/envs/Machine_learning_python2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO</th>\n",
       "      <th>ChrtNum</th>\n",
       "      <th>DIST</th>\n",
       "      <th>Level_Number</th>\n",
       "      <th>Perc5HFZ_aerobic</th>\n",
       "      <th>Perc5NI_aerobic</th>\n",
       "      <th>Perc5NI_HR_aerobic</th>\n",
       "      <th>Perc7HFZ_aerobic</th>\n",
       "      <th>Perc7NI_aerobic</th>\n",
       "      <th>Perc7NI_HR_aerobic</th>\n",
       "      <th>...</th>\n",
       "      <th>Year</th>\n",
       "      <th>Perc5HFZ_bodycomp</th>\n",
       "      <th>Perc5NI_bodycomp</th>\n",
       "      <th>Perc5NI_HR_bodycomp</th>\n",
       "      <th>Perc7HFZ_bodycomp</th>\n",
       "      <th>Perc7NI_bodycomp</th>\n",
       "      <th>Perc7NI_HR_bodycomp</th>\n",
       "      <th>Perc9HFZ_bodycomp</th>\n",
       "      <th>Perc9NI_bodycomp</th>\n",
       "      <th>Perc9NI_HR_bodycomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73965.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>25.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>58.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73965.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>42.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>39.8</td>\n",
       "      <td>22.9</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO ChrtNum     DIST  Level_Number Perc5HFZ_aerobic Perc5NI_aerobic  \\\n",
       "0  10.0    0000  73965.0           1.0             66.1            25.8   \n",
       "1  10.0    0000  73965.0           1.0              0.0             0.0   \n",
       "2  10.0    0000  73999.0           1.0              0.0             0.0   \n",
       "3  10.0    0000  73999.0           1.0             41.5            42.4   \n",
       "4  10.0    0000  73999.0           1.0              0.0             0.0   \n",
       "\n",
       "  Perc5NI_HR_aerobic Perc7HFZ_aerobic Perc7NI_aerobic Perc7NI_HR_aerobic  \\\n",
       "0                8.1              0.0             0.0                0.0   \n",
       "1                0.0             78.0            11.9               10.1   \n",
       "2                0.0               **              **                 **   \n",
       "3               16.1              0.0             0.0                0.0   \n",
       "4                0.0              0.0             0.0                0.0   \n",
       "\n",
       "          ...          Year Perc5HFZ_bodycomp Perc5NI_bodycomp  \\\n",
       "0         ...          2014              58.9             21.0   \n",
       "1         ...          2014               0.0              0.0   \n",
       "2         ...          2014               0.0              0.0   \n",
       "3         ...          2014              39.8             22.9   \n",
       "4         ...          2014               0.0              0.0   \n",
       "\n",
       "  Perc5NI_HR_bodycomp  Perc7HFZ_bodycomp  Perc7NI_bodycomp  \\\n",
       "0                20.1                0.0               0.0   \n",
       "1                 0.0               65.6              16.3   \n",
       "2                 0.0                 **                **   \n",
       "3                37.3                0.0               0.0   \n",
       "4                 0.0                0.0               0.0   \n",
       "\n",
       "  Perc7NI_HR_bodycomp Perc9HFZ_bodycomp Perc9NI_bodycomp Perc9NI_HR_bodycomp  \n",
       "0                 0.0               0.0              0.0                 0.0  \n",
       "1                18.1               0.0              0.0                 0.0  \n",
       "2                  **               0.0              0.0                 0.0  \n",
       "3                 0.0               0.0              0.0                 0.0  \n",
       "4                 0.0                **               **                  **  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Physfit_df.shape\n",
    "\n",
    "#Keep only summaries of certain fitness tests\n",
    "Physfit_df_2 = Physfit_df.loc[Physfit_df.Table_Number == 1]\n",
    "\n",
    "#Keep only Aerobic capacity and body composition reports\n",
    "#remove trailing spaces from line descriptor\n",
    "Physfit_df_2['Line_Text'] = Physfit_df_2['Line_Text'].map(lambda x: x.strip())\n",
    "Physfit_df_2 = Physfit_df_2.loc[(Physfit_df_2.Line_Text == \"Aerobic Capacity\") | (Physfit_df_2.Line_Text == \"Body Composition\")]\n",
    "\n",
    "#Remove state level summaries\n",
    "Physfit_df_2 = Physfit_df_2.loc[Physfit_df_2.Level_Number != 4]\n",
    "\n",
    "#Remove summary report numbers - these were already removed in the first subset step that kept only summaries of individual fitness tests\n",
    "Physfit_df_2 = Physfit_df_2.loc[Physfit_df_2.Report_Number < 14]\n",
    "\n",
    "#********************************\n",
    "#Convert to wide format\n",
    "#Take aerobic capacity and body comp subsets\n",
    "Physfit_df_2a = Physfit_df_2.loc[Physfit_df_2.Line_Text == \"Aerobic Capacity\"]\n",
    "Physfit_df_2b = Physfit_df_2.loc[Physfit_df_2.Line_Text == \"Body Composition\"]\n",
    "\n",
    "#rename columns\n",
    "body_comp_col_dict = {}\n",
    "body_comp_col_dict['NoHFZ5'] = 'NoHFZ5_bodycomp'\n",
    "body_comp_col_dict['NoHFZ7'] = 'NoHFZ7_bodycomp'\n",
    "body_comp_col_dict['NoHFZ9'] = 'NoHFZ9_bodycomp'\n",
    "\n",
    "body_comp_col_dict['NoStud5'] = 'NoStud5_bodycomp'\n",
    "body_comp_col_dict['NoStud7'] = 'NoStud7_bodycomp'\n",
    "body_comp_col_dict['NoStud9'] = 'NoStud9_bodycomp'\n",
    "\n",
    "body_comp_col_dict['Perc5a'] = 'Perc5HFZ_bodycomp'\n",
    "body_comp_col_dict['Perc5b'] = 'Perc5NI_bodycomp'\n",
    "body_comp_col_dict['Perc5c'] = 'Perc5NI_HR_bodycomp'\n",
    "\n",
    "body_comp_col_dict['Perc7a'] = 'Perc7HFZ_bodycomp'\n",
    "body_comp_col_dict['Perc7b'] = 'Perc7NI_bodycomp'\n",
    "body_comp_col_dict['Perc7c'] = 'Perc7NI_HR_bodycomp'\n",
    "\n",
    "body_comp_col_dict['Perc9a'] = 'Perc9HFZ_bodycomp'\n",
    "body_comp_col_dict['Perc9b'] = 'Perc9NI_bodycomp'\n",
    "body_comp_col_dict['Perc9c'] = 'Perc9NI_HR_bodycomp'\n",
    "\n",
    "\n",
    "aero_col_dict = {}\n",
    "aero_col_dict['NoHFZ5'] = 'NoHFZ5_aerobic'\n",
    "aero_col_dict['NoHFZ7'] = 'NoHFZ7_aerobic'\n",
    "aero_col_dict['NoHFZ9'] = 'NoHFZ9_aerobic'\n",
    "\n",
    "aero_col_dict['NoStud5'] = 'NoStud5_aerobic'\n",
    "aero_col_dict['NoStud7'] = 'NoStud7_aerobic'\n",
    "aero_col_dict['NoStud9'] = 'NoStud9_aerobic'\n",
    "\n",
    "aero_col_dict['Perc5a'] = 'Perc5HFZ_aerobic'\n",
    "aero_col_dict['Perc5b'] = 'Perc5NI_aerobic'\n",
    "aero_col_dict['Perc5c'] = 'Perc5NI_HR_aerobic'\n",
    "\n",
    "aero_col_dict['Perc7a'] = 'Perc7HFZ_aerobic'\n",
    "aero_col_dict['Perc7b'] = 'Perc7NI_aerobic'\n",
    "aero_col_dict['Perc7c'] = 'Perc7NI_HR_aerobic'\n",
    "\n",
    "aero_col_dict['Perc9a'] = 'Perc9HFZ_aerobic'\n",
    "aero_col_dict['Perc9b'] = 'Perc9NI_aerobic'\n",
    "aero_col_dict['Perc9c'] = 'Perc9NI_HR_aerobic'\n",
    "\n",
    "\n",
    "Physfit_df_2a = Physfit_df_2a.rename(columns = aero_col_dict)\n",
    "Physfit_df_2b = Physfit_df_2b.rename(columns = body_comp_col_dict)\n",
    "\n",
    "#delete line number and test descriptor columns which also identifies the fitness metric\n",
    "Physfit_df_2a = Physfit_df_2a.drop(['Line_Number', 'Line_Text'], axis = 1)\n",
    "Physfit_df_2b = Physfit_df_2b.drop(['Line_Number', 'Line_Text'], axis = 1)\n",
    "\n",
    "#merge\n",
    "Physfit_df_2_comb = pd.merge(left = Physfit_df_2a, right = Physfit_df_2b, how = 'inner')\n",
    "\n",
    "#Add labels to the subgroup identifiers\n",
    "subgroup_label_dict = {}\n",
    "#These mappings are based on the data descriptions\n",
    "subgroup_label_dict[0] = 'All'\n",
    "subgroup_label_dict[1] = 'Female'\n",
    "subgroup_label_dict[2] = 'Male'\n",
    "subgroup_label_dict[3] = 'Black'\n",
    "subgroup_label_dict[4] = 'American_Indian'\n",
    "subgroup_label_dict[5] = 'Asian'\n",
    "subgroup_label_dict[6] = 'Filipino'\n",
    "subgroup_label_dict[7] = 'Hispanic'\n",
    "subgroup_label_dict[8] = 'Hawaiian'\n",
    "subgroup_label_dict[9] = 'White'\n",
    "subgroup_label_dict[10] = 'Multiracial'\n",
    "subgroup_label_dict[11] = 'Economic_disadv'\n",
    "subgroup_label_dict[12] = 'NOT_economic_disadv'\n",
    "subgroup_label_dict[13] = 'No_economic_info'\n",
    "\n",
    "Physfit_df_2_comb = Physfit_df_2_comb.replace({\"Report_Number\": subgroup_label_dict})\n",
    "\n",
    "#Drop the columns counting the number of students in each group\n",
    "Physfit_df_2_comb = Physfit_df_2_comb.drop(['NoHFZ5_aerobic', 'NoHFZ7_aerobic', 'NoHFZ9_aerobic', 'NoStud5_aerobic', 'NoStud7_aerobic', 'NoStud9_aerobic',\\\n",
    "                                           'NoHFZ5_bodycomp', 'NoHFZ7_bodycomp', 'NoHFZ9_bodycomp', 'NoStud5_bodycomp', 'NoStud7_bodycomp', 'NoStud9_bodycomp'], \\\n",
    "                                          axis = 1)\n",
    "\n",
    "Physfit_df_2_comb.head()\n",
    "\n",
    "#Physfit_df_2.head()\n",
    "#print Physfit_df_2_comb.columns\n",
    "#print Physfit_df_2_comb.shape\n",
    "#Physfit_df_2b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize lists to hold filepaths\n",
    "academic_files_list = []\n",
    "academic_entities_files_list = []\n",
    "\n",
    "#Walk the data directory and get all filepaths\n",
    "for root, dirs, files in os.walk(academic_datapath):\n",
    "    for filename in files:\n",
    "        #Get full list of filepaths to the physical fitness test files\n",
    "        if filename[7:10] == \"all\":    \n",
    "            academic_files_list.append(academic_datapath + \"/\" + filename[2:6] + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Test_Results/2014/ca2014_all_csv_v2.txt',\n",
       " '/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Test_Results/2015/ca2015_all_csv_v3.txt',\n",
       " '/Users/nwchen24/Desktop/UC_Berkeley/w209_Data_Viz/final_project_data/Test_Results/2016/ca2016_all_csv_v3.txt']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "(1177424, 21)\n",
      "Index([u'County Code', u'District Code', u'School Code', u'Charter Number',\n",
      "       u'Test Year', u'Subgroup ID', u'Test Type', u'CAPA Assessment Level',\n",
      "       u'Total Tested At Entity Level', u'Total Tested At Subgroup Level',\n",
      "       u'Grade', u'Test Id', u'Students Tested', u'Mean Scale Score',\n",
      "       u'Percentage Advanced', u'Percentage Proficient',\n",
      "       u'Percentage At Or Above Proficient', u'Percentage Basic',\n",
      "       u'Percentage Below Basic', u'Percentage Far Below Basic',\n",
      "       u'Students with Scores'],\n",
      "      dtype='object')\n",
      "2015\n",
      "(727771, 21)\n",
      "Index([u'County Code', u'District Code', u'School Code', u'filler',\n",
      "       u'Test Year', u'Subgroup ID', u'Test Type', u'CAPA Assessment Level',\n",
      "       u'Total Tested At Entity Level', u'Total Tested At Subgroup Level',\n",
      "       u'Grade', u'Test Id', u'Students Tested', u'Mean Scale Score',\n",
      "       u'Percentage Advanced', u'Percentage Proficient',\n",
      "       u'Percentage At Or Above Proficient', u'Percentage Basic',\n",
      "       u'Percentage Below Basic', u'Percentage Far Below Basic',\n",
      "       u'Students with Scores'],\n",
      "      dtype='object')\n",
      "2016\n",
      "(262313, 22)\n",
      "Index([u'County Code', u'District Code', u'School Code', u'filler',\n",
      "       u'Test Year', u'Subgroup ID', u'Test Type',\n",
      "       u'CAPA Science Assessment Level', u'Total CAASPP Enrollment',\n",
      "       u'Total Tested At Entity Level', u'Total Students with Scores',\n",
      "       u'Grade', u'Test Id', u'Students Tested', u'Mean Scale Score',\n",
      "       u'Percentage Advanced', u'Percentage Proficient',\n",
      "       u'Percentage At Or Above Proficient', u'Percentage Basic',\n",
      "       u'Percentage Below Basic', u'Percentage Far Below Basic',\n",
      "       u'Students with Scores'],\n",
      "      dtype='object')\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#get list of all columns in the file from each year\n",
    "academic_col_list = []\n",
    "\n",
    "#read PhysFit files and append column names to the list\n",
    "for filepath in academic_files_list:\n",
    "    #read the file\n",
    "    temp_df = pd.read_csv(filepath)\n",
    "    #print the shape\n",
    "    print filepath[89:93]\n",
    "    print temp_df.shape\n",
    "    #get the columns\n",
    "    temp_col_list = temp_df.columns\n",
    "    print temp_col_list\n",
    "    #add columns not already encountered to the column list\n",
    "    for colname in temp_col_list:\n",
    "        if colname not in academic_col_list:\n",
    "            academic_col_list.append(colname)\n",
    "            \n",
    "print len(academic_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['County Code',\n",
       " 'District Code',\n",
       " 'School Code',\n",
       " 'Charter Number',\n",
       " 'Test Year',\n",
       " 'Subgroup ID',\n",
       " 'Test Type',\n",
       " 'Grade',\n",
       " 'Test Id',\n",
       " 'Mean Scale Score']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#academic_col_list.remove('filler')\n",
    "academic_col_list.remove('CAPA Assessment Level')\n",
    "academic_col_list.remove('CAPA Science Assessment Level')\n",
    "academic_col_list.remove('Total CAASPP Enrollment')\n",
    "academic_col_list.remove('Total Students with Scores')\n",
    "academic_col_list.remove('Students Tested')\n",
    "academic_col_list.remove('Total Tested At Subgroup Level')\n",
    "academic_col_list.remove('Total Tested At Entity Level')\n",
    "academic_col_list.remove('Percentage Advanced')\n",
    "academic_col_list.remove('Percentage Proficient')\n",
    "academic_col_list.remove('Percentage At Or Above Proficient')\n",
    "academic_col_list.remove('Percentage Basic')\n",
    "academic_col_list.remove('Percentage Below Basic')\n",
    "academic_col_list.remove('Percentage Far Below Basic')\n",
    "academic_col_list.remove('Students with Scores')\n",
    "academic_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 Read Successfully\n",
      "2015 Read Successfully\n",
      "2016 Read Successfully\n"
     ]
    }
   ],
   "source": [
    "academic_df = pd.DataFrame(columns = academic_col_list)\n",
    "\n",
    "#read PhysFit files\n",
    " \n",
    "\n",
    "for filepath in academic_files_list:\n",
    "    temp_df = pd.read_csv(filepath)\n",
    "    #temp_df = temp_df.rename(columns = Physfit_column_mapping)\n",
    "    academic_df = academic_df.append(temp_df)\n",
    "    print filepath[89:93] + \" Read Successfully\"\n",
    "\n",
    "#Keep only the columns that we want\n",
    "academic_df = academic_df.drop(['CAPA Assessment Level', 'CAPA Science Assessment Level', 'Total CAASPP Enrollment',\\\n",
    "                               'Total Students with Scores', 'Students Tested', 'Total Tested At Subgroup Level',\\\n",
    "                               'Total Tested At Entity Level', 'Percentage Advanced', 'Percentage Proficient',\\\n",
    "                               'Percentage At Or Above Proficient', 'Percentage Basic', 'Percentage Below Basic',\\\n",
    "                               'Percentage Far Below Basic', 'Students with Scores', 'filler'], axis = 1)\n",
    "\n",
    "#replace spaces in column names with underscores\n",
    "academic_df.columns = [c.replace(' ', '_') for c in academic_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Subset the academic data to only the observations we're interested in.\n",
    "#See subgroup ID mappings here: http://caaspp.cde.ca.gov/caaspp2015/research_fixfileformat.aspx\n",
    "#We want all students, and the following subgroups individually:\n",
    "#male, female, black, american indian, asian, filipino, hispanic, hawaiian, white, multiracial, economically disadvantaged, not ecnonomically disadvantaged, and non economic info\n",
    "\n",
    "#instantiate dict to map subgroup IDs to the groups we're interested in\n",
    "subgroup_label_dict = {}\n",
    "\n",
    "subgroup_label_dict[1] = 'All'\n",
    "subgroup_label_dict[4] = 'Female'\n",
    "subgroup_label_dict[3] = 'Male'\n",
    "subgroup_label_dict[74] = 'Black'\n",
    "subgroup_label_dict[75] = 'American_Indian'\n",
    "subgroup_label_dict[76] = 'Asian'\n",
    "subgroup_label_dict[77] = 'Filipino'\n",
    "subgroup_label_dict[78] = 'Hispanic'\n",
    "subgroup_label_dict[79] = 'Hawaiian'\n",
    "subgroup_label_dict[80] = 'White'\n",
    "subgroup_label_dict[144] = 'Multiracial'\n",
    "subgroup_label_dict[31] = 'Economic_disadv'\n",
    "subgroup_label_dict[111] = 'NOT_economic_disadv'\n",
    "\n",
    "#Keep only observations for the subgroups we're interested in\n",
    "academic_df_2 = academic_df.loc[academic_df.Subgroup_ID.isin([1.0, 4.0, 3.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 144.0, 31.0, 111.0])]\n",
    "\n",
    "#Keep only grades 5, 7, and 9\n",
    "academic_df_2 = academic_df_2.loc[academic_df_2.Grade.isin([5.0, 7.0, 9.0])]\n",
    "\n",
    "#convert mean scale score to numeric\n",
    "academic_df_2['Mean_Scale_Score'] = academic_df_2['Mean_Scale_Score'].apply(pd.to_numeric, errors = \"NA\")\n",
    "\n",
    "#Get average score for these three grades for each school\n",
    "academic_df_2 = academic_df_2.drop(['Grade', 'Test_Id', 'Test_Type'], axis = 1)\n",
    "academic_df_2 = academic_df_2.groupby(['Charter_Number', 'County_Code', 'District_Code', 'School_Code', 'Subgroup_ID', 'Test_Year'], as_index=False).mean()\n",
    "\n",
    "#relabel subgroup IDs\n",
    "academic_df_2 = academic_df_2.replace({\"Subgroup_ID\": subgroup_label_dict})\n",
    "\n",
    "#Mean academic test scores now ready to merge with fitnessgram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'County_Code', u'Charter_Number', u'District_Code', u'Level_Number',\n",
       "       u'Perc5HFZ_aerobic', u'Perc5NI_aerobic', u'Perc5NI_HR_aerobic',\n",
       "       u'Perc7HFZ_aerobic', u'Perc7NI_aerobic', u'Perc7NI_HR_aerobic',\n",
       "       u'Perc9HFZ_aerobic', u'Perc9NI_aerobic', u'Perc9NI_HR_aerobic',\n",
       "       u'Subgroup', u'School_Code', u'Year', u'Perc5HFZ_bodycomp',\n",
       "       u'Perc5NI_bodycomp', u'Perc5NI_HR_bodycomp', u'Perc7HFZ_bodycomp',\n",
       "       u'Perc7NI_bodycomp', u'Perc7NI_HR_bodycomp', u'Perc9HFZ_bodycomp',\n",
       "       u'Perc9NI_bodycomp', u'Perc9NI_HR_bodycomp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Physfit_df_2_comb.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Academic Results with Fitnessgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename academic data columns to facilitate merge\n",
    "Physfit_col_mapping = {}\n",
    "Physfit_col_mapping['CO'] = 'County_Code'\n",
    "Physfit_col_mapping['ChrtNum'] = 'Charter_Number'\n",
    "Physfit_col_mapping['DIST'] = 'District_Code'\n",
    "Physfit_col_mapping['SCHL'] = 'School_Code'\n",
    "Physfit_col_mapping['Report_Number'] = 'Subgroup'\n",
    "\n",
    "academic_col_mapping = {}\n",
    "academic_col_mapping['Test_Year'] = 'Year'\n",
    "academic_col_mapping['Subgroup_ID'] = 'Subgroup'\n",
    "academic_col_mapping['Mean_Scale_Score'] = 'Mean_Academic_Test_Score'\n",
    "\n",
    "academic_df_2 = academic_df_2.rename(columns = academic_col_mapping)\n",
    "Physfit_df_2_comb = Physfit_df_2_comb.rename(columns = Physfit_col_mapping)\n",
    "\n",
    "#convert year to numeric in fitnessgram dataset\n",
    "Physfit_df_2_comb['Year'] = Physfit_df_2_comb['Year'].apply(pd.to_numeric, errors = \"NA\")\n",
    "\n",
    "#delete table number from fitnessgram dataset (only one value)\n",
    "#del Physfit_df_2_comb['Table_Number']\n",
    "\n",
    "#Keep only school level observations\n",
    "Physfit_df_2_comb = Physfit_df_2_comb.loc[Physfit_df_2_comb.Level_Number == 1]\n",
    "#academic_df_2 = academic_df_2.loc[academic_df_2.School_Code > 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charter_Number              float64\n",
       "County_Code                 float64\n",
       "District_Code               float64\n",
       "School_Code                 float64\n",
       "Subgroup                     object\n",
       "Year                        float64\n",
       "Mean_Academic_Test_Score    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_df_2.head()\n",
    "academic_df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "County_Code            float64\n",
       "Charter_Number          object\n",
       "District_Code          float64\n",
       "Level_Number           float64\n",
       "Perc5HFZ_aerobic        object\n",
       "Perc5NI_aerobic         object\n",
       "Perc5NI_HR_aerobic      object\n",
       "Perc7HFZ_aerobic        object\n",
       "Perc7NI_aerobic         object\n",
       "Perc7NI_HR_aerobic      object\n",
       "Perc9HFZ_aerobic        object\n",
       "Perc9NI_aerobic         object\n",
       "Perc9NI_HR_aerobic      object\n",
       "Subgroup                object\n",
       "School_Code            float64\n",
       "Year                     int64\n",
       "Perc5HFZ_bodycomp       object\n",
       "Perc5NI_bodycomp        object\n",
       "Perc5NI_HR_bodycomp     object\n",
       "Perc7HFZ_bodycomp       object\n",
       "Perc7NI_bodycomp        object\n",
       "Perc7NI_HR_bodycomp     object\n",
       "Perc9HFZ_bodycomp       object\n",
       "Perc9NI_bodycomp        object\n",
       "Perc9NI_HR_bodycomp     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Physfit_df_2_comb.head()\n",
    "Physfit_df_2_comb.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376819, 25)\n",
      "(69982, 7)\n"
     ]
    }
   ],
   "source": [
    "#Merge\n",
    "print Physfit_df_2_comb.shape\n",
    "print academic_df_2.shape\n",
    "\n",
    "combined_DF = pd.merge(left = Physfit_df_2_comb, right = academic_df_2, how = 'inner', on = ['County_Code', 'District_Code', 'School_Code', 'Subgroup', 'Year'])\n",
    "print combined_DF.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE TO DO  \n",
    "\n",
    "There are a lot of observations in the fitnessgram dataset that do not show up in the academic test results data. We need to figure out why there are so many missing observations. The cells below are intended to investigate the observations in the fitnessgram dataset that do not appear in the test results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "\n",
    "unmerged_df = pd.merge(left = Physfit_df_2_comb, right = academic_df_2, how = 'left', on = ['County_Code', 'District_Code', 'School_Code', 'Subgroup', 'Year'])\n",
    "\n",
    "unmerged_df = combined_DF.loc[unmerged_df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Charter_Number_x</th>\n",
       "      <th>District_Code</th>\n",
       "      <th>Level_Number</th>\n",
       "      <th>Perc5HFZ_aerobic</th>\n",
       "      <th>Perc5NI_aerobic</th>\n",
       "      <th>Perc5NI_HR_aerobic</th>\n",
       "      <th>Perc7HFZ_aerobic</th>\n",
       "      <th>Perc7NI_aerobic</th>\n",
       "      <th>Perc7NI_HR_aerobic</th>\n",
       "      <th>Perc9HFZ_aerobic</th>\n",
       "      <th>Perc9NI_aerobic</th>\n",
       "      <th>Perc9NI_HR_aerobic</th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>School_Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Perc5HFZ_bodycomp</th>\n",
       "      <th>Perc5NI_bodycomp</th>\n",
       "      <th>Perc5NI_HR_bodycomp</th>\n",
       "      <th>Perc7HFZ_bodycomp</th>\n",
       "      <th>Perc7NI_bodycomp</th>\n",
       "      <th>Perc7NI_HR_bodycomp</th>\n",
       "      <th>Perc9HFZ_bodycomp</th>\n",
       "      <th>Perc9NI_bodycomp</th>\n",
       "      <th>Perc9NI_HR_bodycomp</th>\n",
       "      <th>Charter_Number_y</th>\n",
       "      <th>Mean_Academic_Test_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73965.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>All</td>\n",
       "      <td>6120539.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>All</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>All</td>\n",
       "      <td>1033422.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>All</td>\n",
       "      <td>1033430.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0000</td>\n",
       "      <td>73999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>All</td>\n",
       "      <td>6006696.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   County_Code Charter_Number_x  District_Code  Level_Number Perc5HFZ_aerobic  \\\n",
       "1         10.0             0000        73965.0           1.0              0.0   \n",
       "2         10.0             0000        73999.0           1.0              0.0   \n",
       "4         10.0             0000        73999.0           1.0              0.0   \n",
       "5         10.0             0000        73999.0           1.0              0.0   \n",
       "7         10.0             0000        73999.0           1.0              0.0   \n",
       "\n",
       "  Perc5NI_aerobic Perc5NI_HR_aerobic Perc7HFZ_aerobic Perc7NI_aerobic  \\\n",
       "1             0.0                0.0             78.0            11.9   \n",
       "2             0.0                0.0               **              **   \n",
       "4             0.0                0.0              0.0             0.0   \n",
       "5             0.0                0.0              0.0             0.0   \n",
       "7             0.0                0.0             77.3            13.5   \n",
       "\n",
       "  Perc7NI_HR_aerobic Perc9HFZ_aerobic Perc9NI_aerobic Perc9NI_HR_aerobic  \\\n",
       "1               10.1              0.0             0.0                0.0   \n",
       "2                 **              0.0             0.0                0.0   \n",
       "4                0.0               **              **                 **   \n",
       "5                0.0             72.5            20.3                7.2   \n",
       "7                9.2              0.0             0.0                0.0   \n",
       "\n",
       "  Subgroup  School_Code  Year Perc5HFZ_bodycomp Perc5NI_bodycomp  \\\n",
       "1      All    6120539.0  2014               0.0              0.0   \n",
       "2      All          1.0  2014               0.0              0.0   \n",
       "4      All    1033422.0  2014               0.0              0.0   \n",
       "5      All    1033430.0  2014               0.0              0.0   \n",
       "7      All    6006696.0  2014               0.0              0.0   \n",
       "\n",
       "  Perc5NI_HR_bodycomp Perc7HFZ_bodycomp Perc7NI_bodycomp Perc7NI_HR_bodycomp  \\\n",
       "1                 0.0              65.6             16.3                18.1   \n",
       "2                 0.0                **               **                  **   \n",
       "4                 0.0               0.0              0.0                 0.0   \n",
       "5                 0.0               0.0              0.0                 0.0   \n",
       "7                 0.0              54.1             18.6                27.3   \n",
       "\n",
       "  Perc9HFZ_bodycomp Perc9NI_bodycomp Perc9NI_HR_bodycomp  Charter_Number_y  \\\n",
       "1               0.0              0.0                 0.0               NaN   \n",
       "2               0.0              0.0                 0.0               NaN   \n",
       "4                **               **                  **               NaN   \n",
       "5              61.2             24.3                14.5               NaN   \n",
       "7               0.0              0.0                 0.0               NaN   \n",
       "\n",
       "   Mean_Academic_Test_Score  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "4                       NaN  \n",
       "5                       NaN  \n",
       "7                       NaN  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save serialized version to file\n",
    "Physfit_df.to_pickle(combined_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Fitness Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to have been a change in reporting procedure in 2012. Starting in 2012, for each of the grades 5, 7, and 9, the percentage of students not in the healthy fitness zone is split between 'Needs Improvement' and 'High Risk'. We will want to determine whether the cutoff to determine whether students not in the healthy fitness zone remained the same after this reporting change was implemented.\n",
    "\n",
    "Report_Number (and possibly report type) reports the group being reported on in that observation (e.g. all students, male students, female students, black students, white students, etc).\n",
    "\n",
    "Line_Number and Line_Text identify the data being reported (I think this means the particular fitness measuer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Machine_learning_python2]",
   "language": "python",
   "name": "conda-env-Machine_learning_python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
